/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * VoiceAgent v8 â€” Bulletproof Listening + Navigation Guidance
 *
 * FIXES:
 *   1. Recognition starts AFTER greeting finishes (no interference)
 *   2. Route-change detection â†’ speaks screen-specific guidance
 *   3. Robust restart loop with exponential backoff
 *   4. Console logging for every state change (debugging)
 *   5. Post-navigation announcements ("ab consumer number dalein")
 *
 * FLOW:
 *   voiceMode=true â†’ auto-activate â†’ GREET â†’ wait for greeting end
 *   â†’ START recognition â†’ listen â†’ process â†’ stream Gemini â†’ TTS
 *   â†’ route changes â†’ announce new screen â†’ keep listening
 *   â†’ barge-in: user speaks during TTS â†’ cancel â†’ listen
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import { useState, useCallback, useRef, useEffect, memo } from 'react';
import { useLocation } from 'react-router-dom';
import VoiceContext from './VoiceContext';
import { streamGeminiResponse, stopSpeaking, speakText, hasApiKeys } from '../utils/geminiVoiceAgent';

const SPEECH_LANGS = {
    en: 'en-IN', hi: 'hi-IN', pa: 'pa-IN', bn: 'bn-IN',
    ta: 'ta-IN', te: 'te-IN', kn: 'kn-IN', mr: 'mr-IN',
};

// â”€â”€ Quick nav keywords (instant, 0ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const NAV_KEYWORDS = {
    electricity: { words: ['bijli', 'electricity', 'electric', 'à¤¬à¤¿à¤œà¤²à¥€', 'à¨¬à¨¿à¨œà¨²à©€', 'light', 'bijlee', 'lite', 'bill'], route: '/bill/electricity' },
    water: { words: ['paani', 'water', 'jal', 'à¤ªà¤¾à¤¨à¥€', 'à¨ªà¨¾à¨£à©€', 'pani'], route: '/bill/water' },
    gas: { words: ['gas', 'à¤—à¥ˆà¤¸', 'à¨—à©ˆà¨¸', 'lpg', 'cylinder'], route: '/bill/gas' },
    complaint: { words: ['complaint', 'shikayat', 'à¤¶à¤¿à¤•à¤¾à¤¯à¤¤', 'à¨¸à¨¼à¨¿à¨•à¨¾à¨‡à¨¤', 'problem', 'samasya', 'à¤¸à¤®à¤¸à¥à¤¯à¤¾'], route: '/complaint' },
    home: { words: ['home', 'ghar', 'shuru', 'à¤¹à¥‹à¤®', 'à¨¹à©‹à¨®'], route: '/' },
    back: { words: ['back', 'peeche', 'wapas', 'à¤ªà¥€à¤›à¥‡', 'à¨ªà¨¿à©±à¨›à©‡', 'vapas'], route: '__BACK__' },
    guest: { words: ['guest', 'quick pay', 'bina login', 'à¤¬à¤¿à¤¨à¤¾ à¤²à¥‰à¤—à¤¿à¤¨', 'à¤•à¥à¤µà¤¿à¤•'], route: '__GUEST__' },
    login: { words: ['login', 'citizen', 'aadhaar', 'à¤¨à¤¾à¤—à¤°à¤¿à¤•', 'à¤²à¥‰à¤—à¤¿à¤¨', 'à¤†à¤§à¤¾à¤°'], route: '__LOGIN__' },
};

function detectNav(text) {
    const lower = text.toLowerCase();
    for (const [, { words, route }] of Object.entries(NAV_KEYWORDS))
        if (words.some(w => lower.includes(w))) return route;
    return null;
}

function isStopCmd(text) {
    return ['stop', 'band karo', 'ruko', 'à¤¬à¤‚à¤¦ à¤•à¤°à¥‹', 'à¤°à¥à¤•à¥‹', 'à¨¬à©°à¨¦', 'chup', 'bye', 'touch mode']
        .some(s => text.toLowerCase().includes(s));
}

// â”€â”€ Screen guidance messages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const SCREEN_GUIDANCE = {
    '/': {
        hi: 'à¤¯à¤¹ à¤¹à¥‹à¤® à¤ªà¥‡à¤œ à¤¹à¥ˆà¥¤ à¤•à¥Œà¤¨ à¤¸à¤¾ à¤¬à¤¿à¤² à¤­à¤°à¤¨à¤¾ à¤¹à¥ˆ? à¤¬à¤¿à¤œà¤²à¥€, à¤ªà¤¾à¤¨à¥€, à¤¯à¤¾ à¤—à¥ˆà¤¸?',
        en: 'This is the home page. Which bill? Electricity, water, or gas?',
    },
    '/bill/electricity': {
        hi: 'à¤¬à¤¿à¤œà¤²à¥€ à¤¬à¤¿à¤² à¤ªà¥‡à¤œ à¤–à¥à¤² à¤—à¤¯à¤¾à¥¤ à¤…à¤¬ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤¨à¤‚à¤¬à¤° à¤ªà¥ˆà¤¡ à¤¸à¥‡ consumer number à¤¡à¤¾à¤²à¥‡à¤‚, à¤¯à¤¾ à¤¬à¥‹à¤²à¥‡à¤‚à¥¤',
        en: 'Electricity bill page is open. Enter your consumer number using the keypad below, or tell me.',
    },
    '/bill/water': {
        hi: 'à¤ªà¤¾à¤¨à¥€ à¤¬à¤¿à¤² à¤ªà¥‡à¤œ à¤–à¥à¤² à¤—à¤¯à¤¾à¥¤ Consumer number à¤¡à¤¾à¤²à¥‡à¤‚à¥¤',
        en: 'Water bill page is open. Enter your consumer number.',
    },
    '/bill/gas': {
        hi: 'à¤—à¥ˆà¤¸ à¤¬à¤¿à¤² à¤ªà¥‡à¤œ à¤–à¥à¤² à¤—à¤¯à¤¾à¥¤ Consumer number à¤¡à¤¾à¤²à¥‡à¤‚à¥¤',
        en: 'Gas bill page is open. Enter your consumer number.',
    },
    '/complaint': {
        hi: 'à¤¶à¤¿à¤•à¤¾à¤¯à¤¤ à¤ªà¥‡à¤œ à¤–à¥à¤² à¤—à¤¯à¤¾à¥¤ à¤¨à¥€à¤šà¥‡ à¤¸à¥‡ à¤¶à¥à¤°à¥‡à¤£à¥€ à¤šà¥à¤¨à¥‡à¤‚, à¤¯à¤¾ à¤®à¥à¤à¥‡ à¤¬à¤¤à¤¾à¤à¤‚ à¤•à¥à¤¯à¤¾ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤¹à¥ˆà¥¤',
        en: 'Complaint page is open. Choose a category below, or tell me your issue.',
    },
};

const VoiceAgent = memo(function VoiceAgent({
    lang, setLang, screen, setScreen, voiceMode,
    navigate, setCitizen, addLog, children,
}) {
    const [isActive, setIsActive] = useState(false);
    const [status, setStatus] = useState('idle');
    const [lastTranscript, setLastTranscript] = useState('');
    const [lastReply, setLastReply] = useState('');
    const [interimText, setInterimText] = useState('');

    const isActiveRef = useRef(false);
    const isSpeakingRef = useRef(false);
    const recognitionRef = useRef(null);
    const langRef = useRef(lang);
    const screenRef = useRef(screen);
    const processingRef = useRef(false);
    const bargedInRef = useRef(false);
    const silenceTimerRef = useRef(null);
    const lastInterimRef = useRef('');
    const lastRouteRef = useRef('');
    const restartCountRef = useRef(0);
    const maxRestartsRef = useRef(50);

    const location = useLocation();

    useEffect(() => { langRef.current = lang; }, [lang]);
    useEffect(() => { screenRef.current = screen; }, [screen]);

    // â”€â”€ LOG HELPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const log = useCallback((msg) => {
        console.log(`[VoiceAgent] ${msg}`);
        addLog?.(msg);
    }, [addLog]);

    // â”€â”€ TTS (speak and wait for it to finish) â”€â”€â”€â”€â”€â”€â”€
    const ttsSpeak = useCallback((text, langCode) => {
        return new Promise((resolve) => {
            if (!window.speechSynthesis || !text) { resolve(); return; }
            window.speechSynthesis.cancel();

            const u = new SpeechSynthesisUtterance(text);
            u.lang = SPEECH_LANGS[langCode] || 'hi-IN';
            u.rate = 1.05;
            u.pitch = 1;
            u.volume = 1;

            const voices = window.speechSynthesis.getVoices();
            const v = voices.find(v => v.lang === u.lang) || voices.find(v => v.lang.startsWith(langCode));
            if (v) u.voice = v;

            u.onend = () => {
                isSpeakingRef.current = false;
                resolve();
            };
            u.onerror = () => {
                isSpeakingRef.current = false;
                resolve();
            };

            isSpeakingRef.current = true;
            setStatus('speaking');
            window.speechSynthesis.speak(u);
        });
    }, []);

    // â”€â”€ Queue TTS (append without cancelling) â”€â”€â”€â”€â”€â”€â”€
    const queueTTS = useCallback((text, langCode) => {
        return new Promise((resolve) => {
            if (!window.speechSynthesis || !text || bargedInRef.current) { resolve(); return; }

            const u = new SpeechSynthesisUtterance(text);
            u.lang = SPEECH_LANGS[langCode] || 'hi-IN';
            u.rate = 1.05;
            u.pitch = 1;
            u.volume = 1;

            const voices = window.speechSynthesis.getVoices();
            const v = voices.find(v => v.lang === u.lang) || voices.find(v => v.lang.startsWith(langCode));
            if (v) u.voice = v;

            u.onend = () => resolve();
            u.onerror = () => resolve();
            window.speechSynthesis.speak(u);
        });
    }, []);

    // â•â•â• RECOGNITION â€” BULLETPROOF LOOP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    const startRecognition = useCallback(() => {
        const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SR) { log('âŒ SpeechRecognition not supported!'); return; }
        if (!isActiveRef.current) return;

        // Stop any existing
        try { recognitionRef.current?.abort(); } catch { }

        const r = new SR();
        r.lang = SPEECH_LANGS[langRef.current] || 'hi-IN';
        r.continuous = true;
        r.interimResults = true;
        r.maxAlternatives = 1;

        r.onstart = () => {
            log('ğŸ§ Recognition STARTED');
            restartCountRef.current = 0;
            if (!isSpeakingRef.current) setStatus('listening');
        };

        r.onresult = (e) => {
            const last = e.results[e.results.length - 1];

            // â”€â”€ BARGE-IN â”€â”€
            if (isSpeakingRef.current) {
                log('ğŸ”‡ BARGE-IN detected!');
                window.speechSynthesis.cancel();
                isSpeakingRef.current = false;
                bargedInRef.current = true;
                setStatus('listening');
            }

            if (last.isFinal) {
                const t = last[0].transcript.trim();
                log(`ğŸ“ Final: "${t}"`);
                lastInterimRef.current = '';
                setInterimText('');
                clearTimeout(silenceTimerRef.current);
                if (t.length > 1 && !processingRef.current) {
                    handleTranscript(t);
                }
            } else {
                const interim = last[0].transcript;
                lastInterimRef.current = interim;
                setInterimText(interim);
                if (!isSpeakingRef.current) setStatus('listening');

                // Silence fallback timer â€” if no new results for 1.5s, process
                clearTimeout(silenceTimerRef.current);
                silenceTimerRef.current = setTimeout(() => {
                    const t = lastInterimRef.current?.trim();
                    if (t && t.length > 2 && !processingRef.current) {
                        log(`â±ï¸ Silence timer: processing "${t}"`);
                        handleTranscript(t);
                        lastInterimRef.current = '';
                        setInterimText('');
                    }
                }, 1500);
            }
        };

        r.onerror = (e) => {
            log(`âš ï¸ Recognition error: ${e.error}`);
            if (['no-speech', 'aborted'].includes(e.error)) {
                if (isActiveRef.current) {
                    const delay = Math.min(500 * (restartCountRef.current + 1), 3000);
                    restartCountRef.current++;
                    if (restartCountRef.current < maxRestartsRef.current) {
                        setTimeout(() => startRecognition(), delay);
                    }
                }
                return;
            }
            // Other errors: retry with delay
            if (isActiveRef.current && restartCountRef.current < maxRestartsRef.current) {
                restartCountRef.current++;
                setTimeout(() => startRecognition(), 1500);
            }
        };

        r.onend = () => {
            log('ğŸ”„ Recognition ended, restarting...');
            if (isActiveRef.current && restartCountRef.current < maxRestartsRef.current) {
                restartCountRef.current++;
                setTimeout(() => startRecognition(), 300);
            }
        };

        recognitionRef.current = r;
        try {
            r.start();
            log('ğŸš€ Recognition .start() called');
        } catch (err) {
            log(`âŒ Recognition .start() failed: ${err.message}`);
            if (isActiveRef.current) setTimeout(() => startRecognition(), 1000);
        }
    }, [log]);

    // â•â•â• PROCESS TRANSCRIPT â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    const handleTranscript = useCallback(async (transcript) => {
        if (processingRef.current) return;
        processingRef.current = true;
        bargedInRef.current = false;

        setLastTranscript(transcript);
        setInterimText('');
        lastInterimRef.current = '';
        setStatus('processing');
        log(`ğŸ¤ Processing: "${transcript}"`);

        // Stop command
        if (isStopCmd(transcript)) {
            setLastReply('à¤ à¥€à¤• à¤¹à¥ˆ, à¤¬à¤‚à¤¦ à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥‚à¤');
            await ttsSpeak('à¤ à¥€à¤• à¤¹à¥ˆ, à¤¬à¤‚à¤¦ à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥‚à¤à¥¤', langRef.current);
            deactivateVoice();
            processingRef.current = false;
            return;
        }

        // Quick nav detection
        const navRoute = detectNav(transcript);
        if (navRoute) log(`ğŸ—ºï¸ Nav keyword detected: ${navRoute}`);

        // Execute nav immediately for flow actions
        if (navRoute === '__GUEST__') {
            setScreen('guest'); navigate('/');
            setLastReply('à¤ à¥€à¤• à¤¹à¥ˆ, Quick Pay à¤–à¥à¤² à¤°à¤¹à¤¾ à¤¹à¥ˆ');
            await ttsSpeak(langRef.current === 'hi' ? 'à¤ à¥€à¤• à¤¹à¥ˆ, Quick Pay à¤–à¥à¤² à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤ à¤•à¥Œà¤¨ à¤¸à¤¾ à¤¬à¤¿à¤² à¤­à¤°à¤¨à¤¾ à¤¹à¥ˆ?' : 'Opening Quick Pay. Which bill?', langRef.current);
            if (isActiveRef.current) setStatus('listening');
            processingRef.current = false;
            return;
        }
        if (navRoute === '__LOGIN__') {
            setScreen('citizen-auth');
            setLastReply('à¤ à¥€à¤• à¤¹à¥ˆ, à¤²à¥‰à¤—à¤¿à¤¨ à¤ªà¥‡à¤œ à¤–à¥à¤² à¤°à¤¹à¤¾ à¤¹à¥ˆ');
            await ttsSpeak(langRef.current === 'hi' ? 'à¤ à¥€à¤• à¤¹à¥ˆ, à¤²à¥‰à¤—à¤¿à¤¨ à¤ªà¥‡à¤œ à¤–à¥à¤² à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤' : 'Opening login page.', langRef.current);
            if (isActiveRef.current) setStatus('listening');
            processingRef.current = false;
            return;
        }
        if (navRoute === '__BACK__') {
            navigate(-1);
            processingRef.current = false;
            return;
        }
        if (navRoute && navRoute !== '__BACK__') {
            navigate(navRoute);
            // Guidance will be spoken by route-change detector
            processingRef.current = false;
            return;
        }

        // â”€â”€ No quick nav â†’ ask Gemini â”€â”€
        if (!hasApiKeys()) {
            log('âŒ No API keys!');
            setLastReply('API keys missing');
            await ttsSpeak('API keys are not configured. Please check your .env file.', 'en');
            if (isActiveRef.current) setStatus('listening');
            processingRef.current = false;
            return;
        }

        try {
            let fullReply = '';
            let firstSent = false;
            let geminiNav = null;

            const result = await streamGeminiResponse(
                transcript,
                langRef.current,
                `${screenRef.current} | ${window.location.pathname}`,
                async (sentence, idx) => {
                    if (bargedInRef.current) return;
                    fullReply += (idx > 0 ? ' ' : '') + sentence;
                    setLastReply(fullReply);

                    if (idx === 0) {
                        isSpeakingRef.current = true;
                        setStatus('speaking');
                        firstSent = true;
                    }

                    if (!bargedInRef.current) await queueTTS(sentence, langRef.current);
                }
            );

            // Fallback if streaming didn't fire
            if (!firstSent && result.reply && !bargedInRef.current) {
                setLastReply(result.reply);
                isSpeakingRef.current = true;
                await ttsSpeak(result.reply, langRef.current);
            }

            // Gemini navigation
            if (result.intent === 'navigate' && result.action_key) {
                const routes = { electricity: '/bill/electricity', water: '/bill/water', gas: '/bill/gas', complaint: '/complaint', home: '/' };
                geminiNav = routes[result.action_key];
                if (geminiNav) {
                    log(`ğŸ¤– Gemini nav: ${geminiNav}`);
                    navigate(geminiNav);
                }
            } else if (result.intent === 'set_screen') {
                if (result.action_key === 'quick_pay') { setScreen('guest'); navigate('/'); }
                else if (result.action_key === 'citizen_login') setScreen('citizen-auth');
            } else if (result.intent === 'go_back') navigate(-1);

        } catch (err) {
            log(`âŒ Gemini error: ${err.message}`);
            if (!bargedInRef.current) {
                setLastReply('à¤®à¤¾à¤« à¤•à¥€à¤œà¤¿à¤, à¤«à¤¿à¤° à¤¸à¥‡ à¤¬à¥‹à¤²à¥‡à¤‚');
                await ttsSpeak(langRef.current === 'hi' ? 'à¤®à¤¾à¤«à¤¼ à¤•à¥€à¤œà¤¿à¤, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤¿à¤° à¤¸à¥‡ à¤¬à¥‹à¤²à¥‡à¤‚à¥¤' : 'Sorry, please try again.', langRef.current);
            }
        }

        isSpeakingRef.current = false;
        if (isActiveRef.current && !bargedInRef.current) setStatus('listening');
        processingRef.current = false;
    }, [navigate, setScreen, log, ttsSpeak, queueTTS]);

    // â•â•â• ROUTE CHANGE DETECTION (guidance) â•â•â•â•â•â•â•â•â•â•â•

    useEffect(() => {
        if (!isActiveRef.current || !voiceMode) return;
        const currentPath = location.pathname;

        // Only speak guidance when route actually changes
        if (currentPath !== lastRouteRef.current) {
            const prevRoute = lastRouteRef.current;
            lastRouteRef.current = currentPath;

            // Don't speak guidance for the very first route (greeting handles it)
            if (!prevRoute) return;

            // Don't speak if we're currently processing (Gemini response is already speaking)
            if (processingRef.current) return;

            const guidance = SCREEN_GUIDANCE[currentPath];
            if (guidance) {
                const text = guidance[langRef.current] || guidance.en;
                log(`ğŸ“ Route â†’ ${currentPath}: "${text}"`);
                setLastReply(text);

                // Wait a moment for the page to render, then speak
                setTimeout(async () => {
                    if (isActiveRef.current && !processingRef.current) {
                        await ttsSpeak(text, langRef.current);
                        if (isActiveRef.current) setStatus('listening');
                    }
                }, 600);
            }
        }
    }, [location.pathname, voiceMode, log, ttsSpeak]);

    // â•â•â• ACTIVATE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    const activateVoice = useCallback(async () => {
        if (isActiveRef.current) return;
        isActiveRef.current = true;
        setIsActive(true);
        setLastTranscript('');
        setLastReply('');
        setInterimText('');
        stopSpeaking();
        restartCountRef.current = 0;
        lastRouteRef.current = window.location.pathname;
        log('ğŸŸ¢ Voice ACTIVATED');

        // Screen-specific greeting
        const greetings = {
            gateway: {
                hi: 'à¤ à¥€à¤• à¤¹à¥ˆ! à¤¬à¤¤à¤¾à¤‡à¤ â€” à¤¬à¤¿à¤¨à¤¾ à¤²à¥‰à¤—à¤¿à¤¨ à¤•à¥‡ Quick Pay à¤•à¤°à¤¨à¤¾ à¤¹à¥ˆ, à¤¯à¤¾ Citizen à¤²à¥‰à¤—à¤¿à¤¨?',
                en: 'Tell me â€” Quick Pay without login, or Citizen login?',
                pa: 'à¨¦à©±à¨¸à©‹ â€” à¨¬à¨¿à¨¨à¨¾à¨‚ à¨²à©Œà¨—à¨‡à¨¨ Quick Pay, à¨œà¨¾à¨‚ Citizen à¨²à©Œà¨—à¨‡à¨¨?',
            },
            guest: {
                hi: 'à¤¬à¥‹à¤²à¤¿à¤, à¤•à¥Œà¤¨ à¤¸à¤¾ à¤¬à¤¿à¤² à¤­à¤°à¤¨à¤¾ à¤¹à¥ˆ â€” à¤¬à¤¿à¤œà¤²à¥€, à¤ªà¤¾à¤¨à¥€, à¤¯à¤¾ à¤—à¥ˆà¤¸?',
                en: 'Which bill would you like to pay â€” electricity, water, or gas?',
                pa: 'à¨¦à©±à¨¸à©‹, à¨•à¨¿à¨¹à©œà¨¾ à¨¬à¨¿à©±à¨² à¨­à¨°à¨¨à¨¾ à¨¹à©ˆ â€” à¨¬à¨¿à¨œà¨²à©€, à¨ªà¨¾à¨£à©€, à¨œà¨¾à¨‚ à¨—à©ˆà¨¸?',
            },
            'citizen-dashboard': {
                hi: 'à¤¬à¥‹à¤²à¤¿à¤, à¤•à¥à¤¯à¤¾ à¤•à¤°à¤¨à¤¾ à¤¹à¥ˆ â€” à¤¬à¤¿à¤² à¤­à¤°à¤¨à¤¾, à¤¶à¤¿à¤•à¤¾à¤¯à¤¤, à¤¯à¤¾ à¤•à¥à¤› à¤”à¤°?',
                en: 'What would you like to do â€” pay a bill, file a complaint, or something else?',
            },
            'citizen-auth': {
                hi: 'à¤²à¥‰à¤—à¤¿à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¸à¥‡ à¤¤à¤°à¥€à¤•à¤¾ à¤šà¥à¤¨à¥‡à¤‚ â€” à¤…à¤‚à¤—à¥‚à¤ à¤¾, à¤†à¤à¤–, à¤¯à¤¾ OTPà¥¤',
                en: 'Choose a login method below â€” thumb, iris, or OTP.',
            },
        };
        const g = greetings[screenRef.current] || greetings.gateway;
        const text = g[langRef.current] || g.en;

        setLastReply(text);
        setStatus('speaking');

        // Speak greeting FIRST, then start recognition AFTER
        await ttsSpeak(text, langRef.current);

        // NOW start listening (after greeting is done)
        if (isActiveRef.current) {
            log('ğŸ“¢ Greeting done â†’ starting recognition');
            setStatus('listening');
            startRecognition();
        }
    }, [startRecognition, log, ttsSpeak]);

    // â•â•â• DEACTIVATE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    const deactivateVoice = useCallback(() => {
        isActiveRef.current = false;
        setIsActive(false);
        setStatus('idle');
        setInterimText('');
        isSpeakingRef.current = false;
        processingRef.current = false;
        stopSpeaking();
        clearTimeout(silenceTimerRef.current);
        try { recognitionRef.current?.abort(); } catch { }
        log('ğŸ”´ Voice DEACTIVATED');
    }, [log]);

    // Auto-activate when voiceMode is on and screen changes (first time)
    useEffect(() => {
        if (voiceMode && !isActiveRef.current && screen !== 'idle') {
            log('ğŸ”„ Auto-activate: voiceMode=true, screen=' + screen);
            activateVoice();
        }
    }, [voiceMode, screen, activateVoice, log]);

    // Cleanup
    useEffect(() => {
        return () => {
            isActiveRef.current = false;
            try { recognitionRef.current?.abort(); } catch { }
            stopSpeaking();
        };
    }, []);

    const ctx = {
        voiceMode, isActive, status, lastTranscript, lastReply,
        activate: activateVoice, deactivate: deactivateVoice,
    };

    return (
        <VoiceContext.Provider value={ctx}>
            {children}

            {/* â•â•â• VOICE STATUS BAR â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
            {isActive && (
                <div className={`vo-bar vo-bar-${status}`}>
                    <div className="vo-bar-left">
                        {status === 'listening' && (
                            <>
                                <div className="vo-pulse" />
                                <span className="vo-bar-label">
                                    {interimText ? `"${interimText}"` : (lang === 'hi' ? 'ğŸ§ à¤¬à¥‹à¤²à¤¿à¤...' : 'ğŸ§ Speak...')}
                                </span>
                            </>
                        )}
                        {status === 'processing' && (
                            <>
                                <div className="vo-spinner" />
                                <span className="vo-bar-label">{lang === 'hi' ? 'ğŸ§  à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥‚à¤...' : 'ğŸ§  Thinking...'}</span>
                            </>
                        )}
                        {status === 'speaking' && (
                            <>
                                <div className="vo-waves">
                                    {[...Array(4)].map((_, i) => (
                                        <div key={i} className="vo-wave" style={{ animationDelay: `${i * 0.12}s` }} />
                                    ))}
                                </div>
                                <span className="vo-bar-reply">
                                    {lastReply?.substring(0, 100)}{lastReply?.length > 100 ? '...' : ''}
                                </span>
                            </>
                        )}
                    </div>
                    <button className="vo-bar-close"
                        onClick={status === 'speaking'
                            ? () => {
                                stopSpeaking();
                                isSpeakingRef.current = false;
                                bargedInRef.current = true;
                                setStatus('listening');
                            }
                            : deactivateVoice}>
                        {status === 'speaking' ? 'â­' : 'âœ•'}
                    </button>
                </div>
            )}
        </VoiceContext.Provider>
    );
});

export default VoiceAgent;
